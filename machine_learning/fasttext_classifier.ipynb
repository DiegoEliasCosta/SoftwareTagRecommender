{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "76n89uqzw3aB",
    "outputId": "1bbc6fec-50ca-4d09-b929-dcc98ea3321c"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/fastText.git\n",
    "# !pip install ./fastText/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bywOt17faaHu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import json as j\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "from functools import partial\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qKEkBZU0w4iP",
    "outputId": "1279a543-c594-4258-bb25-d167e80b0a92"
   },
   "outputs": [],
   "source": [
    "print('Loading data..')\n",
    "# #randomly split data, test = train_test_split(df, test_size=0.2, shuffle=True), then load data, train,\n",
    "train = pd.read_csv('../data/repps_train.csv')\n",
    "test = pd.read_csv('../data/repos_test.csv')\n",
    "topics_column = 'github_topics_top'\n",
    "text_column = 'input_text_freq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4v1Fj2jaaIM"
   },
   "outputs": [],
   "source": [
    "def make_fasttext_train(d,file):\n",
    "    __ = \"\\n\"\n",
    "    with open(file,\"w\") as file:\n",
    "        for _,i in d.iterrows():\n",
    "            res = \"\"\n",
    "            for j in str(i[topics_column]).split(','):\n",
    "                res += f'__label__{j} '\n",
    "            \n",
    "            res+= f'{str(i[text_column]).replace(__,\" \")}'\n",
    "            file.write(res+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpfVCkIfaaIP"
   },
   "outputs": [],
   "source": [
    "#prepare the data for fasttext\n",
    "make_fasttext_train(train,'train.txt')\n",
    "make_fasttext_train(test,'test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDHRcNqNaaIS"
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"train.txt\",lr=0.05, epoch=100, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0LpBwnnWaaIV",
    "outputId": "ebb365b0-1989-4932-c904-dda2d05fbb5e"
   },
   "outputs": [],
   "source": [
    "model.test(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TblJ42DVaaIa",
    "outputId": "3c7a2bf5-c179-4a43-e816-8d3739e81c5a"
   },
   "outputs": [],
   "source": [
    "model.test(\"test.txt\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAn8ZZL2aYQ5",
    "outputId": "0f63e973-f7cb-4026-ffaf-df43b0b01634"
   },
   "outputs": [],
   "source": [
    "model.test(\"test.txt\", k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9fM6iKSaYRA",
    "outputId": "b02c39b6-32bc-4769-b4ee-22135e2aa549"
   },
   "outputs": [],
   "source": [
    "model.test(\"test.txt\", k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IiM0GuJh8q4"
   },
   "outputs": [],
   "source": [
    "train[topics_column] = train[topics_column].astype(str)\n",
    "_ = list(train[topics_column].map(lambda x: x.split(',')))\n",
    "_ = [i for s in _ for i in s]\n",
    "topics_list = list(set(_))\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[topics_column] = test[topics_column].astype(str)\n",
    "def get_binary_list(topics):\n",
    "    l = [0] * len(topics_list)\n",
    "    for topic in topics.split(','):\n",
    "        l[topics_list.index(topic)] = 1\n",
    "    return l\n",
    "\n",
    "y_pred = []\n",
    "y_original = []\n",
    "for i in test[topics_column]:\n",
    "    y_original.append(get_binary_list(i))\n",
    "\n",
    "for i in test[text_column]:\n",
    "    x = model.predict(i, k=-1, threshold=0)\n",
    "    l = [0] * len(topics_list)\n",
    "    for j,k in zip(x[0],x[1]):\n",
    "        l[topics_list.index(j.replace(\"__label__\",\"\"))] = k\n",
    "    y_pred.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "-XrsNFH-fVAI",
    "outputId": "0ce6ca8c-f9ab-4ebc-d53c-76e615b2ad1e"
   },
   "outputs": [],
   "source": [
    "num_selected_labels = len(topics_list)\n",
    "def eval(text, ts):\n",
    "    def calc(p1, p2, func, **kwargs):\n",
    "        p2 = [list(map(lambda x: 1 if x > 0.5 else 0,y)) for y in p2]\n",
    "        return func(p1, p2, **kwargs)\n",
    "\n",
    "    def calc_recom(p1, p2, func, **kwargs):\n",
    "        return func(p1, p2, **kwargs)\n",
    "\n",
    "    def success_rate(y_original, y_pred):\n",
    "        common = 0\n",
    "        for i in range(0, len(y_pred)):\n",
    "            if(sum(np.array(y_original[i]) * np.array(y_pred[i]))) > 0:\n",
    "                common = common +1\n",
    "        success = common/len(y_pred)\n",
    "        return success\n",
    "\n",
    "    def coverage(y_original,y_pred):\n",
    "        x =  np.sum(y_pred, axis = 0)\n",
    "        c = np.count_nonzero(x > 0)\n",
    "        cov = c / num_selected_labels\n",
    "        return cov    \n",
    "\n",
    "    def prf_at_k(y_original, y_pred_probab):\n",
    "        org_label_count_vec = np.sum(y_original, axis=1)\n",
    "        repo_2_tags = len(np.where(org_label_count_vec >= 2)[0])\n",
    "        repo_5_tags = len(np.where(org_label_count_vec >= 5)[0])        \n",
    "        k_list = [1, 2, 3, 5, 8, 10]\n",
    "        s1, s5 = {}, {}\n",
    "        r, p,f =  {}, {}, {}\n",
    "        y_org_array = np.array(y_original)\n",
    "        for k in k_list:\n",
    "            org_label_count = np.sum(y_org_array, axis=1).tolist()\n",
    "            top_ind = []\n",
    "            top_ind =  np.argpartition(y_pred_probab, -1 * k, axis=1)[:, -1 * k:]\n",
    "            pred_in_org = y_org_array[np.arange(len(y_org_array))[:, None], top_ind]\n",
    "            common_topk = np.sum(pred_in_org, axis=1)\n",
    "\n",
    "            recall, precision, f1 = [], [], []\n",
    "            success1, success5 = 0, 0\n",
    "            for index, value in enumerate(common_topk):    \n",
    "                recall.append(value/min(k, org_label_count[index]))\n",
    "                precision.append(value/k)\n",
    "\n",
    "                if (value >= 1): success1 += 1          \n",
    "                if (value >= 5): success5 += 1         \n",
    "\n",
    "            s1.update({'S1@'+str(k): \"{:.2f}\".format((success1/len(y_original))*100)})\n",
    "            s5.update({'S5@'+str(k): \"{:.2f}\".format((success5/repo_5_tags)*100)})\n",
    "            r.update({'R@'+str(k): \"{:.2f}\".format(np.mean(recall)*100)})           \n",
    "            p.update({'P@'+str(k): \"{:.2f}\".format(np.mean(precision)*100)})\n",
    "            f1 = stats.hmean([precision, recall])\n",
    "            f.update({'F1@'+str(k): \"{:.2f}\".format(np.mean(f1)*100)})\n",
    "        return r, p, f, s1, s5\n",
    "\n",
    "    metrics = {\n",
    "        \"Success_Rate\": partial(calc,func=success_rate),\n",
    "        \"Coverage\": partial(calc,func=coverage),\n",
    "        \"LRL\": partial(calc,func=sklearn.metrics.label_ranking_loss),\n",
    "        \"AUC_micro\": partial(calc,func=sklearn.metrics.roc_auc_score, average='micro'),\n",
    "        \"AUC_macro\": partial(calc,func=sklearn.metrics.roc_auc_score, average='macro'),\n",
    "        \"AUC_wighted\": partial(calc,func=sklearn.metrics.roc_auc_score, average='weighted'),\n",
    "        \"Coverage_err\": partial(calc,func=sklearn.metrics.coverage_error),\n",
    "        \"Avg_P_score_micro\": partial(calc,func=sklearn.metrics.average_precision_score, average='micro'),\n",
    "        \"Avg_P_score_macro\": partial(calc,func=sklearn.metrics.average_precision_score, average='macro'),     \n",
    "        \"f1_micro\": partial(calc,func=sklearn.metrics.f1_score,average='micro'),\n",
    "        \"f1_macro\": partial(calc,func=sklearn.metrics.f1_score,average='macro'),\n",
    "        \"f1_weighted\": partial(calc,func=sklearn.metrics.f1_score,average='weighted'),\n",
    "        \"f1_samples\": partial(calc,func=sklearn.metrics.f1_score,average='samples'),\n",
    "        \"prec_micro\": partial(calc,func=sklearn.metrics.precision_score,average='micro'),\n",
    "        \"prec_macro\": partial(calc,func=sklearn.metrics.precision_score,average='macro'),\n",
    "        \"prec_weighted\": partial(calc,func=sklearn.metrics.precision_score,average='weighted'),\n",
    "        \"prec_samples\": partial(calc,func=sklearn.metrics.precision_score,average='samples'),\n",
    "        \"recall_micro\": partial(calc,func=sklearn.metrics.recall_score,average='micro'),\n",
    "        \"recall_macro\": partial(calc,func=sklearn.metrics.recall_score,average='macro'),\n",
    "        \"recall_weighted\": partial(calc,func=sklearn.metrics.recall_score,average='weighted'),\n",
    "        \"recall_samples\": partial(calc,func=sklearn.metrics.recall_score,average='samples'),\n",
    "        \"hamming_loss\": partial(calc,func=sklearn.metrics.hamming_loss),\n",
    "        \"exact_match_ratio\": partial(calc,func=sklearn.metrics.accuracy_score),\n",
    "        \"R@k\": partial(calc_recom,func=prf_at_k)\n",
    "    }\n",
    "\n",
    "    results = {i:metrics[i](y_original, y_pred) for i in metrics} \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval(y_original, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.predict(list(test[text_column][:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('fasttext_model')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "fast_text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
